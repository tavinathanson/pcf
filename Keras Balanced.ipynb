{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from skimage.data import imread\n",
    "from skimage.io import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randint, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_img = 256\n",
    "nb_img_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_pool = 2\n",
    "nb_conv = 3\n",
    "nb_filters = 32\n",
    "nb_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv, border_mode='valid', \n",
    "                        input_shape=(nb_img_depth, nb_img, nb_img)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, nb_conv, nb_conv, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transform import load_training, transform_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(fga):\n",
    "    if fga < 0.1:\n",
    "        return 0\n",
    "    elif fga < 0.2:\n",
    "        return 1\n",
    "    elif fga < 0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training['fga_class'] = training.fga.apply(get_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_pcf(training,\n",
    "                  output_dir=\"data-%d-patches\" % nb_img,\n",
    "                  patch_size=nb_img,\n",
    "                  fga_class_option=True):\n",
    "    patch_num = 0\n",
    "    for i, row in training.iterrows():\n",
    "        row_patches = []\n",
    "        row_output = []\n",
    "        name = row['name']\n",
    "        if fga_class_option:\n",
    "            fga_class = row['fga_class']\n",
    "        else:\n",
    "            fga_class = '0'\n",
    "        print(\"Transforming image %s\" % name)\n",
    "        import sys\n",
    "        sys.stdout.flush()\n",
    "        for kind in [\"DX\", \"TS\"]:\n",
    "            img = imread(\"images/%s/%s-%s.png\" % (kind, name, kind))\n",
    "            img_patches = transform_img(img, name, patch_size=patch_size)\n",
    "            from os import mkdir, path\n",
    "            class_dir = path.join(output_dir, str(fga_class))\n",
    "            if not path.exists(class_dir):\n",
    "                mkdir(class_dir)\n",
    "            for img_patch in img_patches:\n",
    "                with open(path.join(output_dir, \"%s/patch_file_%s_%d\" % (\n",
    "                            fga_class, name, patch_num)), 'w') as f:\n",
    "                    np.save(f, img_patch)\n",
    "                patch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform_pcf(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fga_dict = training.set_index('name').to_dict()['fga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_x_y(training, output_dir=\"data-%d-patches\" % nb_img):\n",
    "    from os import listdir\n",
    "    from numpy.random import choice, seed\n",
    "    seed(1234)\n",
    "    patches = []\n",
    "    outputs = []\n",
    "    for fga_class in sorted(training.fga_class.unique()):\n",
    "        fga_class = str(fga_class)\n",
    "        print(\"Class %s...\" % fga_class)\n",
    "        import sys\n",
    "        sys.stdout.flush()\n",
    "        patch_files = choice(listdir(path.join(output_dir, fga_class)), \n",
    "                                     size=625, replace=False)\n",
    "        for patch_file in patch_files:\n",
    "            name = patch_file.split(\"_\")[2]\n",
    "            fga = fga_dict[name]\n",
    "            patch = np.load(path.join(path.join(output_dir, fga_class), \n",
    "                                      patch_file))\n",
    "            from skimage.feature import canny\n",
    "            from skimage.color import rgb2gray\n",
    "            patch = rgb2gray(patch)\n",
    "            for rot in range(4):\n",
    "                patches.append(np.rot90(patch, k=rot))\n",
    "                outputs.append(fga)\n",
    "    print(\"Merging X...\")\n",
    "    sys.stdout.flush()\n",
    "    X = np.asanyarray(patches)\n",
    "    print(\"Merging y...\")\n",
    "    sys.stdout.flush()\n",
    "    y = np.asanyarray(outputs)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0...\n",
      "Class 1...\n",
      "Class 2...\n",
      "Class 3...\n",
      "Merging X...\n",
      "Merging y...\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_x_y(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.transpose((0, 3, 2, 1))\n",
    "X_train = np.expand_dims(X_train, axis=0).transpose((1, 0, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 264s - loss: 0.2057   \n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 264s - loss: 0.1932   \n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 264s - loss: 0.1929   \n",
      "Epoch 4/10\n",
      "  352/10000 [>.............................] - ETA: 254s - loss: 0.1906"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-ac53a48d0113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    505\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.evaluate(X_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_testing():\n",
    "    testing = pd.read_csv(\"test.csv\", \n",
    "                       header=None,\n",
    "                       names=['name'],\n",
    "                       dtype={'name': object})\n",
    "    return testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing = load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform_pcf(testing, output_dir=\"data-%d-patches-test\" % nb_img, fga_class_option=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_test(testing, output_dir=\"data-%d-patches-test\" % nb_img):\n",
    "    from os import listdir\n",
    "    from numpy.random import choice, seed\n",
    "    seed(1234)\n",
    "    patches = []\n",
    "    outputs = []\n",
    "    for i, row in testing.iterrows():\n",
    "        name = row['name']\n",
    "        print(\"X_test for %s\" % name)\n",
    "        import sys\n",
    "        sys.stdout.flush()\n",
    "        patch_files = [patch_file for patch_file in listdir(path.join(output_dir, '0')) \n",
    "                       if patch_file.split(\"_\")[2] == name]\n",
    "        patch_files = choice(patch_files, size=100, replace=False)\n",
    "        for patch_file in patch_files:\n",
    "            patch = np.load(path.join(path.join(output_dir, '0'), \n",
    "                                      patch_file))\n",
    "            patches.append(patch)\n",
    "        if i > 4:\n",
    "            break\n",
    "    print(\"Merging X...\")\n",
    "    sys.stdout.flush()\n",
    "    X = np.asanyarray(patches)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = get_x_test(testing, output_dir=\"data-%d-patches-test\" % nb_img)\n",
    "X_test = X_test.transpose((0, 3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(X_train) / 10):\n",
    "    predictions.append(model.predict(X_train[i:i + 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "merged = list(itertools.chain(*predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7f420a1b5710>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAENCAYAAAAL98L+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f420a1b5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(merged).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19499093])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1949909])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
