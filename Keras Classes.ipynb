{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from skimage.data import imread\n",
    "from skimage.io import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randint, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_img = 256\n",
    "nb_img_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_pool = 2\n",
    "nb_conv = 3\n",
    "nb_filters = 32\n",
    "nb_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv, border_mode='valid', \n",
    "                        input_shape=(nb_img_depth, nb_img, nb_img)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, nb_conv, nb_conv, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, nb_conv, nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transform import load_training, transform_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(fga):\n",
    "    if fga < 0.1:\n",
    "        return 0\n",
    "    elif fga < 0.2:\n",
    "        return 1\n",
    "    elif fga < 0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training['fga_class'] = training.fga.apply(get_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x7f652e69a090>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmSJEmSJEmSJEmSpLXy/9oPyHY+hcK0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f652e69a210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training.fga_class.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fga</th>\n",
       "      <th>fga_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10549</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21157</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30333</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>33088</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name   fga  fga_class\n",
       "1   10549  0.58          3\n",
       "16  21157  0.66          3\n",
       "35  30333  0.54          3\n",
       "40  33088  0.72          3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[training.fga_class == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_pcf(training,\n",
    "                  output_dir=\"data-256-patches\",\n",
    "                  patch_size=256):\n",
    "    patch_num = 0\n",
    "    for i, row in training.iterrows():\n",
    "        row_patches = []\n",
    "        row_output = []\n",
    "        name = row['name']\n",
    "        fga = row['fga']\n",
    "        fga_class = row['fga_class']\n",
    "        print(\"Transforming image %s\" % name)\n",
    "        import sys\n",
    "        sys.stdout.flush()\n",
    "        for kind in [\"DX\", \"TS\"]:\n",
    "            img = imread(\"images/%s/%s-%s.png\" % (kind, name, kind))\n",
    "            img_patches = transform_img(img, name, patch_size=patch_size)\n",
    "            from os import mkdir, path\n",
    "            class_dir = path.join(output_dir, str(fga_class))\n",
    "            if not path.exists(class_dir):\n",
    "                mkdir(class_dir)\n",
    "            for img_patch in img_patches:\n",
    "                with open(path.join(output_dir, \"%s/patch_file_%s_%d\" % (\n",
    "                            fga_class, name, patch_num)), 'w') as f:\n",
    "                    np.save(f, img_patch)\n",
    "                patch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform_pcf(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_x_y(training, output_dir=\"data-256-patches\"):\n",
    "    from os import listdir\n",
    "    from numpy.random import choice, seed\n",
    "    seed(1234)\n",
    "    patches = []\n",
    "    outputs = []\n",
    "    for fga_class in sorted(training.fga_class.unique()):\n",
    "        fga_class = str(fga_class)\n",
    "        print(\"Class %s...\" % fga_class)\n",
    "        import sys\n",
    "        sys.stdout.flush()\n",
    "        patch_files = choice(listdir(path.join(output_dir, fga_class)), \n",
    "                                     size=625, replace=False)\n",
    "        for patch_file in patch_files:\n",
    "            patch = np.load(path.join(path.join(output_dir, fga_class), \n",
    "                                      patch_file))\n",
    "            for rot in range(4):\n",
    "                patches.append(np.rot90(patch, k=rot))\n",
    "                outputs.append(int(fga_class))\n",
    "    print(\"Merging X...\")\n",
    "    sys.stdout.flush()\n",
    "    X = np.asanyarray(patches)\n",
    "    print(\"Merging y...\")\n",
    "    sys.stdout.flush()\n",
    "    from keras.utils import np_utils\n",
    "    y = np_utils.to_categorical(outputs)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0...\n",
      "Class 1...\n",
      "Class 2...\n",
      "Class 3...\n",
      "Merging X...\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_x_y(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.transpose((0, 3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, nb_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
